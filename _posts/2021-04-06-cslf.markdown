---
layout: post
title: "Learning Implicit Surface Light Fields."
date: 2021-04-06 00:00:00 +0300
description: Learning Texture Representations in Function Space. # Add post description (optional)
img: tex_felds.png # Add image post (optional)
tags: [3D deep learning, continous function as 3D representation] # add tag
---

Implicit representations of 3D objects have recently achieved impressive results on learning-based 3D reconstruction tasks. While existing works use simple texture models to represent object appearance, photo-realistic image synthesis requires reasoning about the complex interplay of light, geometry and surface properties. In this work, we propose a novel implicit representation for capturing the visual appearance of an object in terms of its surface light field. In contrast to existing representations, our implicit model represents surface light fields in a continuous fashion and independent of the geometry. Moreover, we condition the surface light field with respect to the location and color of a small light source. Compared to traditional surface light field models, this allows us to manipulate the light source and relight the object using environment maps. We further demonstrate the capabilities of our model to predict the visual appearance of an unseen object from a single real RGB image and corresponding 3D shape information. As evidenced by our experiments, our model is able to infer rich visual appearance including shadows and specular reflections. Finally, we show that the proposed representation can be embedded into a variational auto-encoder for generating novel appearances that conform to the specified illumination conditions.

[![Paper]()](http://www.cvlibs.net/publications/Oechsle2019ICCV.pdf "Paper")\\
[![Code]()](https://github.com/autonomousvision/texture_fields "Code")\\
[![Video]()](https://youtu.be/pbfeE0qmD2E "Video")